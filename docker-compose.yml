version: "3.8"

services:
  tum-chatbot-backend:
    build:
      context: ./backend
      dockerfile: ../Dockerfile
    container_name: tum-chatbot-backend
    ports:
      - "8080:8080"
    environment:
      # =============================================================================
      # ENVIRONMENT SETTING (REQUIRED)
      # =============================================================================
      # Set to "development" or "production"
      # This controls all environment-specific behavior automatically
      - ENVIRONMENT=${ENVIRONMENT:-production}

      # =============================================================================
      # APPLICATION SETTINGS
      # =============================================================================
      - APP_NAME=${APP_NAME:-TUM Chatbot}
      - APP_VERSION=${APP_VERSION:-1.0.0}

      # =============================================================================
      # API CONFIGURATION (REQUIRED)
      # =============================================================================
      # Google Gemini API Key (Required)
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.5-flash}
      - GEMINI_MAX_TOKENS=${GEMINI_MAX_TOKENS:-4096}
      - GEMINI_TEMPERATURE=${GEMINI_TEMPERATURE:-0.7}

      # =============================================================================
      # SERVER CONFIGURATION
      # =============================================================================
      - SERVER_HOST=${SERVER_HOST:-0.0.0.0}
      - SERVER_PORT=${SERVER_PORT:-8080}
      - REQUEST_TIMEOUT=${REQUEST_TIMEOUT:-30}

      # CORS Configuration
      - ENABLE_CORS=${ENABLE_CORS:-True}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:5173,http://127.0.0.1:3000}

      # Rate Limiting
      - ENABLE_RATE_LIMITING=${ENABLE_RATE_LIMITING:-True}
      - RATE_LIMIT_REQUESTS=${RATE_LIMIT_REQUESTS:-1000}
      - RATE_LIMIT_WINDOW=${RATE_LIMIT_WINDOW:-3600}

      # Session Management
      - SESSION_TIMEOUT=${SESSION_TIMEOUT:-3600}

      # =============================================================================
      # DATABASE CONFIGURATION
      # =============================================================================
      - CHROMA_DB_PATH=${CHROMA_DB_PATH:-/app/data/chroma_db}
      - CHROMA_COLLECTION_NAME=${CHROMA_COLLECTION_NAME:-tum_qa_collection}
      - CHROMA_PERSIST_DIR=${CHROMA_PERSIST_DIR:-/app/data/chroma_db}

      # =============================================================================
      # SEARCH CONFIGURATION
      # =============================================================================
      - SEMANTIC_SEARCH_TOP_K=${SEMANTIC_SEARCH_TOP_K:-5}
      - KEYWORD_SEARCH_TOP_K=${KEYWORD_SEARCH_TOP_K:-5}
      - HYBRID_SEARCH_TOP_K=${HYBRID_SEARCH_TOP_K:-5}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      - SIMILARITY_THRESHOLD=${SIMILARITY_THRESHOLD:-0.3}

      # =============================================================================
      # KNOWLEDGE BASE CONFIGURATION
      # =============================================================================
      - KNOWLEDGE_BASE_PATH=${KNOWLEDGE_BASE_PATH:-/app/TUM_QA.json}
      - MAX_CONTEXT_LENGTH=${MAX_CONTEXT_LENGTH:-4000}
      - CONVERSATION_HISTORY_LIMIT=${CONVERSATION_HISTORY_LIMIT:-12}

      # =============================================================================
      # LOGGING CONFIGURATION
      # =============================================================================
      # Note: LOG_LEVEL and FLASK_DEBUG are automatically set based on ENVIRONMENT
      # Override only if needed: LOG_LEVEL=DEBUG, FLASK_DEBUG=True
      - LOG_LEVEL=${LOG_LEVEL}
      - FLASK_DEBUG=${FLASK_DEBUG}
      - LOG_FILE=${LOG_FILE:-/app/logs/tum_chatbot.log}
      - LOG_FORMAT=${LOG_FORMAT:-%(asctime)s - %(name)s - %(levelname)s - %(message)s}
      - MAX_LOG_SIZE=${MAX_LOG_SIZE:-10485760}
      - LOG_BACKUP_COUNT=${LOG_BACKUP_COUNT:-5}

      # Chat Session Logging (automatically disabled in production)
      - LOG_CHAT_SESSIONS=${LOG_CHAT_SESSIONS}
      - CHAT_SESSION_FILE=${CHAT_SESSION_FILE:-/app/logs/chat_sessions.log}

      # =============================================================================
      # STATISTICS AND ANALYTICS
      # =============================================================================
      - ENABLE_STATISTICS=${ENABLE_STATISTICS:-True}
      - STATS_DB_PATH=${STATS_DB_PATH:-/app/data/statistics.db}
      - TRACK_USER_SESSIONS=${TRACK_USER_SESSIONS:-True}
      - TRACK_QUERY_ANALYTICS=${TRACK_QUERY_ANALYTICS:-True}
      - ANONYMIZE_DATA=${ANONYMIZE_DATA:-True}

      # =============================================================================
      # PRODUCTION DEPLOYMENT
      # =============================================================================
      - GUNICORN_WORKERS=${GUNICORN_WORKERS:-4}
    volumes:
      # Persist data between container restarts
      - ./data:/app/data
      - ./logs:/app/logs
      # Mount knowledge base
      - ./backend/TUM_QA.json:/app/TUM_QA.json:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Add a frontend service if needed
  # tum-chatbot-frontend:
  #   build: ./frontend
  #   container_name: tum-chatbot-frontend
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - VITE_API_BASE_URL=http://localhost:8080
  #   depends_on:
  #     - tum-chatbot-backend
  #   restart: unless-stopped

volumes:
  data:
  logs:
